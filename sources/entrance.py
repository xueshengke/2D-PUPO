from keras.preprocessing.image import ImageDataGenerator
from sources.prune_method import prune_batchnorm
from models import interface
from utils import np_sigmoid, binomial, get_list, get_type
import os, sys
import numpy as np
import matplotlib as mpl
mpl.use('Agg')
import matplotlib.pyplot as plt

class Runner:

    def __init__(self, model, config, adapter):
        self.model = model
        self.config = config
        self.instance = adapter
        self.callbacks = adapter.initialize_callbacks()

    def set_callbacks(self, instance=None, ckpt_save_path='', log_dir=''):
        if instance:
            self.callbacks = instance.initialize_callbacks(ckpt_save_path, log_dir)
        else:
            self.callbacks = self.instance.initialize_callbacks(ckpt_save_path, log_dir)
        return self.callbacks

    def train(self, train_set=None, valid_set=None):
        print('-------- Train begin --------')

        if not self.config.data_augmentation:
            print('Not using data augmentation')
            if self.config.use_generator:
                print('Using data generator')
                history = self.model.fit_generator(generator=train_set, validation_data=valid_set,
                                                   steps_per_epoch=self.config.num_train / self.config.batch_size,
                                                   validation_steps=self.config.num_valid / self.config.batch_size,
                                                   epochs=self.config.epochs, shuffle=True, callbacks=self.callbacks,
                                                   workers=1, use_multiprocessing=False, verbose=self.config.verbose)
            else:
                print('Not using data generator')
                history = self.model.fit(train_set[0], {'ift' : train_set[1], 'rec' : train_set[1]},
                                         batch_size=self.config.batch_size, epochs=self.config.epochs,
                                         validation_data=(valid_set[0], {'ift' : valid_set[1], 'rec' : valid_set[1]}),
                                         shuffle=True, verbose=self.config.verbose, callbacks=self.callbacks)
        else:
            print('Using real-time data augmentation')
            # This will do preprocessing and realtime data augmentation:
            datagen = ImageDataGenerator(
                # set input mean to 0 over the dataset
                featurewise_center=False,
                # set each sample mean to 0
                samplewise_center=False,
                # divide inputs by std of dataset
                featurewise_std_normalization=False,
                # divide each input by its std
                samplewise_std_normalization=False,
                # apply ZCA whitening
                zca_whitening=False,
                # epsilon for ZCA whitening
                zca_epsilon=1e-06,
                # randomly rotate images in the range (deg 0 to 180)
                rotation_range=0.,
                # randomly shift images horizontally
                width_shift_range=0.1,
                # randomly shift images vertically
                height_shift_range=0.1,
                # set range for random shear
                shear_range=0.,
                # set range for random zoom
                zoom_range=0.,
                # set range for random channel shifts
                channel_shift_range=0.,
                # set mode for filling points outside the input boundaries
                fill_mode='nearest',
                # value used for fill_mode = "constant"
                cval=0.,
                # randomly flip images
                horizontal_flip=True,
                # randomly flip images
                vertical_flip=True,
                # set rescaling factor (applied before any other transformation)
                rescale=None,
                # set function that will be applied on each input
                preprocessing_function=None,
                # image data format, either "channels_first" or "channels_last"
                data_format=None,
                # fraction of images reserved for validation (strictly between 0 and 1)
                validation_split=0.0)

            # Compute quantities required for featurewise normalization
            # (std, mean, and principal components if ZCA whitening is applied).
            datagen.fit(train_set[0])

            # Fit the models on the batches generated by datagen.flow().
            history = self.model.fit_generator(datagen.flow(train_set[0], train_set[1], batch_size=self.config.batch_size),
                                               validation_data=valid_set, epochs=self.config.epochs,
                                               steps_per_epoch=self.config.num_train / self.config.batch_size,
                                               verbose=self.config.verbose, shuffle=True, callbacks=self.callbacks)
        self.history = history

        print('-------- Train end --------')

        return history

    def validate(self, model=None, test_set=None):
        if model is None:
            model = self.model
        print('-------- Inference begin --------')

        # score trained model
        if self.config.use_generator:
            scores = model.evaluate_generator(test_set, steps=self.config.num_valid / self.config.batch_size,
                                              workers=1, use_multiprocessing=False, verbose=self.config.verbose)
        else:
            scores = model.evaluate(test_set[0], {'ift': test_set[1], 'rec': test_set[1]},
                                    batch_size=self.config.batch_size, verbose=self.config.verbose)

        results = dict(zip(model.metrics_names, scores))
        for name, value in results.items():
            print(name, value)

        self.results = results

        print('-------- Inference end --------')
        return results

    def save_model(self, model=None, result_dir=''):
        if model is None:
            model = self.model
        print('-------- Save model begin --------')

        if result_dir == '':
            result_dir = os.path.join(self.config.root_dir, 'results', self.config.model_type, self.config.run)
        if not os.path.isdir(result_dir):
            os.makedirs(result_dir)
        result_model_name = self.config.model_type + '_{}{:.4f}_{}{:.4f}.h5'.format(
            self.config.record_metrics[0], self.results[self.config.record_metrics[0]],
            self.config.record_metrics[1], self.results[self.config.record_metrics[1]])
        save_model_path = os.path.join(result_dir, result_model_name)
        # model.save_weights(save_model_path) ## save weights only
        model.save(save_model_path, include_optimizer=False)
        print('Saving model to ' + save_model_path)
        print('-------- Save model end --------')
        return save_model_path

    def save_metrics(self, figure_dir='', draw_mask=True):
        if self.config.save_figures:
            print('-------- Save figures begin --------')
            # print(history.history.keys())

            if figure_dir == '':
                figure_dir = os.path.join(self.config.root_dir, 'figures', self.config.model_type, self.config.run,
                                          '{}{:.4f}_{}{:.4f}'.format(
                                          self.config.record_metrics[0], self.results[self.config.record_metrics[0]],
                                          self.config.record_metrics[1], self.results[self.config.record_metrics[1]]))
            else:
                figure_dir = os.path.join(figure_dir, '{}{:.4f}_{}{:.4f}'.format(
                                self.config.record_metrics[0], self.results[self.config.record_metrics[0]],
                                self.config.record_metrics[1], self.results[self.config.record_metrics[1]]))

            if not os.path.exists(figure_dir):
                os.makedirs(figure_dir)

            epochs = self.history.epoch
            metrics = self.history.history
            with open(os.path.join(figure_dir, 'logs.txt'), 'w') as f:
                f.write('epoch : ' + str(epochs) + '\n')
                for key, value in metrics.items():
                    f.write(key + ' : ' + str(value) + '\n')
                for key, value in self.results.items():
                    f.write(key + ' : ' + str(value) + '\n')
                if self.config.run in ['prune', 'atuo']:
                    for key, value in self.prune_info.items():
                        f.write(key + ' : ' + str(value) + '\n')

            pair_keys = ['loss', 'ift_loss', 'rec_loss', 'PSNR', 'SSIM', 'ift_PSNR', 'ift_SSIM', 'rec_PSNR', 'rec_SSIM']
            for key in pair_keys:
                if key in metrics.keys() and 'val_' + key in metrics.keys():
                    plt.figure()
                    plt.plot(epochs, metrics[key])
                    plt.plot(epochs, metrics['val_' + key])
                    plt.grid(True)
                    plt.title(key + ' vs epoch')
                    plt.ylabel(key)
                    plt.xlabel('epoch')
                    plt.legend(['Train', 'Val'], loc='upper left')
                    plt.tight_layout()
                    plt.savefig(os.path.join(figure_dir, key + '_vs_epoch.png'))
                    print('Saving figure at ' + os.path.join(figure_dir, key + '_vs_epoch.png'))
                    plt.show(block=False)
                    plt.pause(0.01)
                    del metrics[key]
                    del metrics['val_' + key]

            for key, value in metrics.items():
                plt.figure()
                plt.plot(epochs, value)
                plt.grid(True)
                plt.title(key + ' vs epoch')
                plt.ylabel(key)
                plt.xlabel('epoch')
                plt.tight_layout()
                plt.savefig(os.path.join(figure_dir, key + '_vs_epoch.png'))
                print('Saving figure at ' + os.path.join(figure_dir, key + '_vs_epoch.png'))
                plt.show(block=False)
                plt.pause(0.01)

            if draw_mask:
                pmask_layer_list = get_list(self.model, ['PMask2D'])
                for i in range(len(pmask_layer_list)):
                    # prob, mask = pmask_layer_list[i].get_weights()[0], pmask_layer_list[i].mask
                    prob = pmask_layer_list[i].get_weights()[0]
                    mask = binomial(prob)
                    prob, mask = np.squeeze(prob), np.squeeze(mask)
                    plt.figure()
                    plt.title('Probability')
                    plt.subplot(1, 2, 1)
                    fig_obj = plt.imshow(prob, cmap=plt.get_cmap('jet'))
                    plt.colorbar(fig_obj)
                    plt.title('Probability (avg=%.4f)' % np.mean(prob))
                    plt.subplot(1, 2, 2)
                    fig_obj = plt.imshow(mask, cmap=plt.get_cmap('gray'))
                    plt.colorbar(fig_obj)
                    plt.title('Mask (%.2f%%)' % (100.0 * np.sum(mask) / mask.size))
                    plt.tight_layout()
                    plt.savefig(os.path.join(figure_dir, 'Parametric_mask.png'))
                    print('Saving figure at ' + os.path.join(figure_dir, 'Parametric_mask.png'))
                    plt.show(block=False)
                    plt.pause(0.01)

            print('-------- Save figures end --------')

    def prune(self, x_train, y_train, x_test, y_test):

        print('-------- Prune begin --------')

        batchnorm_layer_list = [layer for layer in self.model.layers if 'batch_normalization' in layer.name]
        mask_layer_list      = [layer for layer in self.model.layers if 'mask' in layer.name]
        num_layers = len(mask_layer_list)

        for t in range(self.config.prune_steps):
            print('Before prune:')
            self.validate(x_test=x_test, y_test=y_test)

            print('-------- Prune step {}: {}% begin --------'.format(t, self.config.sparsity[t]*100))

            prune_mask_vectors = prune_batchnorm(model=self.model, layer_list=batchnorm_layer_list, sparsity=self.config.sparsity[t])

            for i in range(num_layers):
                mask_layer_list[i].set_weights([ np.reshape(prune_mask_vectors[i], [1, 1, 1, len(prune_mask_vectors[i])]) ])

            print('After prune:')
            self.validate(x_test=x_test, y_test=y_test)

            print('Retrain:')
            ckpt_save_path = os.path.join(self.config.root_dir, 'checkpoints', self.config.model_type,
                                          'prune_%.2f' % self.config.sparsity[t])
            log_dir = os.path.join(self.config.root_dir, 'logs', self.config.model_type,
                                   'prune_%.2f' % self.config.sparsity[t])
            self.callbacks = self.instance.initialize_callbacks(ckpt_save_path=ckpt_save_path, log_dir=log_dir)
            self.train(x_train, y_train, x_test, y_test)

            print('After retrain:')
            self.validate(x_test=x_test, y_test=y_test)

            save_dir = os.path.join(self.config.root_dir, 'results',  self.config.model_type, 'prune_%.2f' % self.config.sparsity[t])
            self.save_model(result_dir=save_dir)

            figure_dir = os.path.join(self.config.root_dir, 'figures', self.config.model_type, 'prune_%.2f' % self.config.sparsity[t])
            self.save_metrics(figure_dir=figure_dir)

            print('-------- Prune step {}: {}% end --------'.format(t, self.config.sparsity[t]*100))

        print('-------- Prune end --------')

    def compress(self):
        print('-------- Compress begin --------')

        conv_layer_list = [layer for layer in self.model.layers if 'conv' in layer.name]
        batchnorm_layer_list = [layer for layer in self.model.layers if 'batch_normalization' in layer.name]
        mask_layer_list = [layer for layer in self.model.layers if 'mask' in layer.name]
        dense_layer_list = [layer for layer in self.model.layers if 'dense' in layer.name]
        num_layers = len(mask_layer_list)

        mask_vector = [None] * num_layers
        final_channel = [None] * num_layers

        # obtain mask and number of channels
        for i in range(num_layers):
            mask = mask_layer_list[i].get_weights()[0]
            mask_vector[i] = mask
            final_channel[i] = int(np.sum(mask))
        print('Final channel: ' + str([(i, mask_layer_list[i].name, final_channel[i]) for i in range(num_layers)]))

        self.config.final_channel = final_channel
        self.config.is_final = True
        self.config.restore_model = False
        self.config.bn_mask = False
        # create final model
        final_instance = interface.ModelAdapter(self.config)
        final_model = final_instance.create_model()
        final_instance.serialize_model()

        final_conv_layer_list = [layer for layer in final_model.layers if 'conv' in layer.name]
        final_batchnorm_layer_list = [layer for layer in final_model.layers if 'batch_normalization' in layer.name]
        final_dense_layer_list = [layer for layer in final_model.layers if 'dense' in layer.name]

        # first conv-bn-mask-relu block
        print('Compress the first conv-bn-mask-relu block ' + conv_layer_list[0].name)
        conv_weights = conv_layer_list[0].get_weights()
        bn_weights = batchnorm_layer_list[0].get_weights()
        cur_mask = mask_vector[0]
        # kernel
        conv_weights[0] *= cur_mask
        conv_weights[0] = conv_weights[0][..., np.where(np.squeeze(cur_mask)==1)[0]]
        # bias
        conv_weights[1] *= np.squeeze(cur_mask)
        conv_weights[1] = conv_weights[1][..., np.where(np.squeeze(cur_mask)==1)[0]]
        # batchnorm: gamma, beta, mean, variance
        for j in range(len(bn_weights)):
            bn_weights[j] *= np.squeeze(cur_mask)
            bn_weights[j] = bn_weights[j][..., np.where(np.squeeze(cur_mask) == 1)[0]]
        # weights transfer
        final_conv_layer_list[0].set_weights(conv_weights)
        final_batchnorm_layer_list[0].set_weights(bn_weights)

        # reduce the in-channel of the convolution in the first Resblock
        conv_weights = conv_layer_list[1].get_weights()
        cur_mask = cur_mask.transpose(0,1,3,2)
        # kernel
        conv_weights[0] *= cur_mask
        conv_weights[0] = conv_weights[0][..., np.where(np.squeeze(cur_mask)==1)[0], :]
        # weight transfer
        final_conv_layer_list[1].set_weights(conv_weights)

        # depth-wise convlutional layers in skip connections
        dwc = [19, 36]
        for idx in dwc:
            print('Compress depth-wise ' + conv_layer_list[idx].name)
            final_conv_layer_list[idx].set_weights(conv_layer_list[idx].get_weights())
        # remove layer names in list
        conv_layer_list = np.delete(conv_layer_list, dwc)
        final_conv_layer_list = np.delete(final_conv_layer_list, dwc)

        # regular conv-bn-mask-relu block weights transfer
        for i in range(1, num_layers):
            print('Compress ' + str((i, conv_layer_list[i].name, batchnorm_layer_list[i].name)))
            conv_weights = conv_layer_list[i].get_weights()
            bn_weights = batchnorm_layer_list[i].get_weights()
            pre_mask = mask_vector[i-1].transpose(0,1,3,2)
            cur_mask = mask_vector[i]
            # kernel
            conv_weights[0] *= cur_mask
            if i % 2 == 1:
                conv_weights[0] = conv_weights[0][..., np.where(np.squeeze(cur_mask) == 1)[0]]
            if i % 2 == 0:
                conv_weights[0] *= pre_mask
                conv_weights[0] = conv_weights[0][..., np.where(np.squeeze(pre_mask) == 1)[0], :]
            # bias
            conv_weights[1] *= np.squeeze(cur_mask)
            if i % 2 == 1:
                conv_weights[1] = conv_weights[1][..., np.where(np.squeeze(cur_mask) == 1)[0]]
            # batchnorm: gamma, beta, mean, variance
            for j in range(len(bn_weights)):
                bn_weights[j] *= np.squeeze(cur_mask)
                if i % 2 == 1:
                    bn_weights[j] = bn_weights[j][..., np.where(np.squeeze(cur_mask) == 1)[0]]
            # weight transfer
            final_conv_layer_list[i].set_weights(conv_weights)
            final_batchnorm_layer_list[i].set_weights(bn_weights)

        # dense layer weights transfer
        for i in range(len(dense_layer_list)):
            print('Compress ' + final_dense_layer_list[i].name)
            final_dense_layer_list[i].set_weights(dense_layer_list[i].get_weights())

        print('-------- Compress end --------')

        return final_model
